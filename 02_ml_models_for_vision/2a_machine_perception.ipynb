{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gwp2BI0uckiq"
   },
   "source": [
    "# 5-Flower Dataset\n",
    "\n",
    "`Machine Perception`\n",
    "- Asking machine learning model to learn to perceive what's in the image\n",
    "\n",
    "`Computer Vision`\n",
    "- Type of perception is analogous to human sight\n",
    "\n",
    "\n",
    "[flower-dataset](https://www.tensorflow.org/datasets/catalog/tf_flowers)\n",
    "- `'Daisy', 'Roses', 'Dandelions', 'Sunflowers' & 'Tuplips'`\n",
    "\n",
    "\n",
    "\n",
    "**should not be used as a template, but as an example**\n",
    "\n",
    "1. Quantity\n",
    "  - to train ML models from scratch, you'll need to collect millions of images\n",
    "  - There are alternative approaches that work with fewer images, but you should attempt to collect the largest dataset that is practical\n",
    "2. Data Format\n",
    "  - Storing the images as individual JPEG files is very inefficient because most of your model training time will be spent waiting for data to be read.\n",
    "  - Better to use TensorFlow Record Format\n",
    "3. Content\n",
    "  - The dataset itself consists of found data - images that were not explicitly collected for the classification task.\n",
    "  - Collect data more puposefully\n",
    "4. Labelling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdSe5PqlhlOs"
   },
   "source": [
    "## Confirming if GPU is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7679,
     "status": "ok",
     "timestamp": 1634126539091,
     "user": {
      "displayName": "Hamzz Gabajiwala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHbkScIsDqdd-VCF79FP0QQKg0_rWF8_YNQsL9lHE=s64",
      "userId": "05553510707788340755"
     },
     "user_tz": -330
    },
    "id": "3FLdQR3ndNxS",
    "outputId": "3792ee1d-b3d8-4e16-cca5-0b50eff92eeb"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# print(tf.version.VERSION)\n",
    "# device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# if device_name != '/device:GPU:0':\n",
    "#   raise SystemError('GPU device not found')\n",
    "# print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaZQ4-OTiJU7"
   },
   "source": [
    "## Examining the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1872,
     "status": "ok",
     "timestamp": 1634131728895,
     "user": {
      "displayName": "Hamzz Gabajiwala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHbkScIsDqdd-VCF79FP0QQKg0_rWF8_YNQsL9lHE=s64",
      "userId": "05553510707788340755"
     },
     "user_tz": -330
    },
    "id": "D1OofLKOiGaZ",
    "outputId": "2235f2e5-edad-4ee5-ab6c-e8ed8ded743b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gsutil' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/train_set.csv | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzLhScaR17Cy"
   },
   "source": [
    "## Reading Image Data\n",
    "\n",
    "1. `img = tf.io.read_file(filename)` Used to read the file and convert it into pixel data - also called decoding\n",
    "2. `img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)` specifying the number of color channels (red, green, blue) from the JPEG\n",
    "3. `img = tf.image.convert_image_dtype(img, tf.float32)` pixel values consist of RGB that are of type uint and in the range of [0, 255], this converts them into a float scale so they lie in the range [0, 1]\n",
    "4. `tf.image.resize(img, reshape_dims)` resizing to a desired shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 627,
     "status": "ok",
     "timestamp": 1634133587390,
     "user": {
      "displayName": "Hamzz Gabajiwala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHbkScIsDqdd-VCF79FP0QQKg0_rWF8_YNQsL9lHE=s64",
      "userId": "05553510707788340755"
     },
     "user_tz": -330
    },
    "id": "qKkTN2RxiWyQ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH  = 224\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1634133588186,
     "user": {
      "displayName": "Hamzz Gabajiwala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHbkScIsDqdd-VCF79FP0QQKg0_rWF8_YNQsL9lHE=s64",
      "userId": "05553510707788340755"
     },
     "user_tz": -330
    },
    "id": "y_AHsXDFioh1"
   },
   "outputs": [],
   "source": [
    "def read_and_decode(filename, reshape_dims):\n",
    "\n",
    "  # Read the file - convert them into pixel data, also called decoding\n",
    "  img = tf.io.read_file(filename)\n",
    "\n",
    "  # Convert the compressed string to a 3D uint8 tensor - specifying the number of \n",
    "  # color channels (red, green, blue) from JPEG\n",
    "  img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
    "\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0, 1] range\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "  # Resize the image to the desired size\n",
    "  return tf.image.resize(img, reshape_dims) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1634127432796,
     "user": {
      "displayName": "Hamzz Gabajiwala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHbkScIsDqdd-VCF79FP0QQKg0_rWF8_YNQsL9lHE=s64",
      "userId": "05553510707788340755"
     },
     "user_tz": -330
    },
    "id": "sIaSjlx8iy9v",
    "outputId": "0c94f4b8-aca3-47f7-93cc-5870a72a7f1a"
   },
   "outputs": [
    {
     "ename": "UnimplementedError",
     "evalue": "File system scheme 'gs' not implemented (file: 'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/*')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f7590b2933b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m CLASS_NAMES = [item.numpy().decode('utf-8')\n\u001b[1;32m----> 2\u001b[1;33m               for item in tf.strings.regex_replace(tf.io.gfile.glob(\"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/*\"),\n\u001b[0m\u001b[0;32m      3\u001b[0m                  \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/\", \"\")]\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# for item in CLASS_NAMES:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mget_matching_files_v2\u001b[1;34m(pattern)\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[1;31m# Convert the filenames to string from bytes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatching_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m         for matching_filename in _pywrap_file_io.GetMatchingFiles(\n\u001b[0m\u001b[0;32m    409\u001b[0m             compat.as_bytes(pattern))\n\u001b[0;32m    410\u001b[0m     ]\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: File system scheme 'gs' not implemented (file: 'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/*')"
     ]
    }
   ],
   "source": [
    "CLASS_NAMES = [item.numpy().decode('utf-8')\n",
    "              for item in tf.strings.regex_replace(tf.io.gfile.glob(\"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/*\"),\n",
    "                 \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/\", \"\")]\n",
    "\n",
    "# for item in CLASS_NAMES:\n",
    "#   if item.find(\".\") == -1:\n",
    "#     print(item)\n",
    "\n",
    "CLASS_NAMES = [item for item in CLASS_NAMES if item.find(\".\") == -1]\n",
    "print(\"These are the available class: \", CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MswnlSLms6l2"
   },
   "source": [
    "## What's a Tensor\n",
    "\n",
    "1D array -> vector\n",
    "\n",
    "2D array -> matrix\n",
    "\n",
    "*tensor* -> an array with any number of dimensions \n",
    "\n",
    "A matrix with 12 rows and 18 columns is said to have a *shape* of (12, 18) and a *rank* of 2\n",
    "\n",
    "`x = np.array([2.0, 3.0, 1.0, 0.0])`\n",
    "\n",
    "`x5d = np.zeros(shape=(4, 3, 7, 8, 3))`\n",
    "\n",
    "For obtaining hardware acceleration use TensorFlow\n",
    "\n",
    "`tx = tx.convert_to_tensor(x, dtype=tf.float32)`\n",
    "\n",
    "converting back to numpy array `x = tx.numpy()`\n",
    "\n",
    "Mathematiclly numpy anf TensorFlow are the same\n",
    "  - numpy arithmetic is done on the CPU\n",
    "  - TensorFlow code runs on GPU \n",
    "\n",
    "`x = x * 0.3` is less efficient than `tx = tx*0.3`\n",
    "\n",
    "**Efficient to vectorize the code so that you can carry out a single in-place tensor operation instead of a bunch of tiny scalar operations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6-GNf2BvTuk"
   },
   "source": [
    "## Visualizing Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 1770,
     "status": "ok",
     "timestamp": 1634127583092,
     "user": {
      "displayName": "Hamzz Gabajiwala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHbkScIsDqdd-VCF79FP0QQKg0_rWF8_YNQsL9lHE=s64",
      "userId": "05553510707788340755"
     },
     "user_tz": -330
    },
    "id": "FI5EkOKIlt8v",
    "outputId": "34a998b0-f236-4297-90f8-80f24f303736"
   },
   "outputs": [],
   "source": [
    "def show_image(filename):\n",
    "  img = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n",
    "  plt.imshow(img.numpy())\n",
    "\n",
    "show_image(\"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/754296579_30a9ae018c_n.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 2500,
     "status": "ok",
     "timestamp": 1634127741385,
     "user": {
      "displayName": "Hamzz Gabajiwala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHbkScIsDqdd-VCF79FP0QQKg0_rWF8_YNQsL9lHE=s64",
      "userId": "05553510707788340755"
     },
     "user_tz": -330
    },
    "id": "5k3jYEmZmA4u",
    "outputId": "2412def1-bed5-4b35-f90e-0b270a5a3f5c"
   },
   "outputs": [],
   "source": [
    "tuplis = tf.io.gfile.glob(\"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/*.jpg\")\n",
    "f, ax = plt.subplots(1, 5, figsize=(15, 15))\n",
    "\n",
    "for idx, filename in enumerate(tuplis[:5]):\n",
    "  print(filename)\n",
    "\n",
    "  img = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n",
    "  ax[idx].imshow((img.numpy()))\n",
    "  ax[idx].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 342,
     "status": "ok",
     "timestamp": 1634127841772,
     "user": {
      "displayName": "Hamzz Gabajiwala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHbkScIsDqdd-VCF79FP0QQKg0_rWF8_YNQsL9lHE=s64",
      "userId": "05553510707788340755"
     },
     "user_tz": -330
    },
    "id": "YAgX3ObWmlh6",
    "outputId": "1888ea26-6bfe-47db-800d-9db79d9e48a8"
   },
   "outputs": [],
   "source": [
    "tf.strings.split(tf.strings.regex_replace(\"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/10094731133_94a942463c.jpg\",\n",
    "    \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/\", \"\"),'/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 2343,
     "status": "ok",
     "timestamp": 1634127979832,
     "user": {
      "displayName": "Hamzz Gabajiwala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHbkScIsDqdd-VCF79FP0QQKg0_rWF8_YNQsL9lHE=s64",
      "userId": "05553510707788340755"
     },
     "user_tz": -330
    },
    "id": "l7oC9Dpom2IJ",
    "outputId": "89ece169-3fbf-47fd-9202-3ff858f20d23"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 5, figsize=(15, 15))\n",
    "\n",
    "for idx, filename in enumerate([\n",
    "  \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/754296579_30a9ae018c_n.jpg\",\n",
    "  \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/3554992110_81d8c9b0bd_m.jpg\",\n",
    "  \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/roses/7420699022_60fa574524_m.jpg\",\n",
    "  \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/sunflowers/21518663809_3d69f5b995_n.jpg\",\n",
    "  \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713398906_28e59a225a_n.jpg\"]):\n",
    "\n",
    "  img = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n",
    "\n",
    "  ax[idx].imshow((img.numpy()))\n",
    "  ax[idx].set_title(CLASS_NAMES[idx])\n",
    "  ax[idx].axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdFJrRLpv04r"
   },
   "source": [
    "## Reading the Dataset File\n",
    "\n",
    "Reading all the images using the wildcard\n",
    "\n",
    "`tf.io.gfile.glob(\"gs://cloud-ml-data/img/flower_photos/*/*.jpg)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 348,
     "status": "ok",
     "timestamp": 1634130386591,
     "user": {
      "displayName": "Hamzz Gabajiwala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHbkScIsDqdd-VCF79FP0QQKg0_rWF8_YNQsL9lHE=s64",
      "userId": "05553510707788340755"
     },
     "user_tz": -330
    },
    "id": "Edf_aG66wOq6",
    "outputId": "5fd58c61-3f65-4c0b-86d4-d0dbb5b2b161"
   },
   "outputs": [],
   "source": [
    "basename = tf.strings.regex_replace(filename, \n",
    "                                    \"gs://cloud-ml-data/img/flower_photos/\", \"\")\n",
    "label = tf.strings.split(basename, '/')[0]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 342,
     "status": "ok",
     "timestamp": 1634130997371,
     "user": {
      "displayName": "Hamzz Gabajiwala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHbkScIsDqdd-VCF79FP0QQKg0_rWF8_YNQsL9lHE=s64",
      "userId": "05553510707788340755"
     },
     "user_tz": -330
    },
    "id": "Hzsdr-zYwqQj"
   },
   "outputs": [],
   "source": [
    "# Specify what TensorFlow needs to erplace in ordr to handle a line where one or more values are missing\n",
    "def decode_csv(csv_row):\n",
    "  record_defaults = ['path', 'flower']\n",
    "  filename, label_string = tf.io.decode_csv(csv_row, record_defaults)\n",
    "  img = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n",
    "  return img, label_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 324,
     "status": "ok",
     "timestamp": 1634131001532,
     "user": {
      "displayName": "Hamzz Gabajiwala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHbkScIsDqdd-VCF79FP0QQKg0_rWF8_YNQsL9lHE=s64",
      "userId": "05553510707788340755"
     },
     "user_tz": -330
    },
    "id": "QEe1pbZjxWJr"
   },
   "outputs": [],
   "source": [
    "dataset = (tf.data.TextLineDataset(\n",
    "    \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/train_set.csv\").\n",
    "    map(decode_csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOj2hAfGzN9e"
   },
   "source": [
    "`take(3)` truncates the datset to three items\n",
    "\n",
    "print out the average pixel value using `tf.reduce_mean()`\n",
    "\n",
    "\n",
    "label -> string tensor\n",
    "\n",
    "```\n",
    "tf.Tensor(b'daisy', shape=(), dtype=string) \n",
    "tf.Tensor([0.3588961  0.36257887 0.26933077], \n",
    "          shape=(3,), dtype=float32)\n",
    "```\n",
    "\n",
    "avg -> 1D tensor of length 3\n",
    "  - we got 1D tensor because of `axis=[0, 1]`\n",
    "\n",
    "`[IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS]` providing an `axis=[0, 1]` we are asking tensor to compute the average of all columns (axis=0) and all rows (axis=1), but not to average the RGB values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 916,
     "status": "ok",
     "timestamp": 1634131006024,
     "user": {
      "displayName": "Hamzz Gabajiwala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHbkScIsDqdd-VCF79FP0QQKg0_rWF8_YNQsL9lHE=s64",
      "userId": "05553510707788340755"
     },
     "user_tz": -330
    },
    "id": "wQzx7aGQzD0j",
    "outputId": "9ba03fdc-93b3-4b59-a753-a58c6a1a7ed5"
   },
   "outputs": [],
   "source": [
    "for img, label in dataset.take(3):\n",
    "  avg = tf.math.reduce_mean(img, axis=[0, 1]) # Average pixel in the image\n",
    "  print(label, avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xx9sdf8h1IEH"
   },
   "source": [
    "## A Linear Model Using Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jycpkp504TgC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPEpe15SSC0atxA/OPfjupW",
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
